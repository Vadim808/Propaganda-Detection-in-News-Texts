{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlDMgYm4lzvd"
   },
   "source": [
    "(https://keras.io/examples/nlp/text_extraction_with_bert/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nl2fRygIlzvi",
    "outputId": "c195a9d2-9d66-4fee-ec98-28e95655b5f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, BertTokenizerFast \n",
    "print(tf.__version__)\n",
    "\n",
    "from learning_checks import hist_graph\n",
    "from learning_checks import text_check\n",
    "from learning_checks import check_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v53lw-ErpMEr"
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "\"Reductio ad hitlerum\",\n",
    "\"Whataboutism\",\n",
    "\"Presenting Irrelevant Data (Red Herring)\",\n",
    "\"Doubt\",\n",
    "\"Slogans\",\n",
    "\"Appeal to fear/prejudice\",\n",
    "\"Obfuscation, Intentional vagueness, Confusion\",\n",
    "\"Misrepresentation of Someone's Position (Straw Man)\",\n",
    "\"Glittering generalities (Virtue)\",\n",
    "\"Appeal to authority\",\n",
    "\"Repetition\",\n",
    "\"Bandwagon\",\n",
    "\"Causal Oversimplification\",\n",
    "\"Name calling/Labeling\",\n",
    "\"Thought-terminating cliché\",\n",
    "\"Flag-waving\",\n",
    "\"Exaggeration/Minimisation\",\n",
    "\"Smears\",\n",
    "\"Loaded Language\",\n",
    "\"Black-and-white Fallacy/Dictatorship\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "97sQkMTNpMEt",
    "outputId": "ccc783ab-29a8-41ce-dac2-1c0a28665ada"
   },
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(\"data.csv\").sample(20)\n",
    "data_pd = data_pd.reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which leads me then to wonder: If they're real...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Putting aside freedom of speech, the persecuti...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No fact-checking</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THAT'S A FACT \\n\\nDID YOU KNOW THE NRA TRAINED...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Smears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It may even prove a political masterstroke of ...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This was, remember, 1965, four years before th...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>But to see the partisans of the defeated candi...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LIBERAL LOGIC: \"DON'T CALL THEM ANIMALS!\"\\n\\n\"...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Thought-terminating cliché</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Orban is openly Christian and seems to underst...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Flag-waving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The handover was done with much fanfare, then ...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The people who talk about the \"Jewish question...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The “Countering Violent Extremism” is trash an...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I BULLSHITTED AND USED BLACKS AND MINORITIES T...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Misrepresentation of Someone's Position (Straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>They deliberately refused to bring up the alle...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Despite the fall of his friend Pineda, Maradia...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>If we wipe out the Coronavirus when the warm w...</td>\n",
       "      <td>[0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Perhaps Arizona will put someone in that actua...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOW DARE YOU NOT VOTERINO FOR HECKIN' BERNERIN...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Less than a week later, Wilson received a lett...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Appeal to fear/prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The ideology that killed over 100 million last...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Appeal to fear/prejudice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Which leads me then to wonder: If they're real...   \n",
       "1   Putting aside freedom of speech, the persecuti...   \n",
       "2                                    No fact-checking   \n",
       "3   THAT'S A FACT \\n\\nDID YOU KNOW THE NRA TRAINED...   \n",
       "4   It may even prove a political masterstroke of ...   \n",
       "5   This was, remember, 1965, four years before th...   \n",
       "6   But to see the partisans of the defeated candi...   \n",
       "7   LIBERAL LOGIC: \"DON'T CALL THEM ANIMALS!\"\\n\\n\"...   \n",
       "8   Orban is openly Christian and seems to underst...   \n",
       "9   The handover was done with much fanfare, then ...   \n",
       "10  The people who talk about the \"Jewish question...   \n",
       "11  The “Countering Violent Extremism” is trash an...   \n",
       "12  I BULLSHITTED AND USED BLACKS AND MINORITIES T...   \n",
       "13  They deliberately refused to bring up the alle...   \n",
       "14  Despite the fall of his friend Pineda, Maradia...   \n",
       "15  If we wipe out the Coronavirus when the warm w...   \n",
       "16  Perhaps Arizona will put someone in that actua...   \n",
       "17  HOW DARE YOU NOT VOTERINO FOR HECKIN' BERNERIN...   \n",
       "18  Less than a week later, Wilson received a lett...   \n",
       "19  The ideology that killed over 100 million last...   \n",
       "\n",
       "                                            prop_mask  \\\n",
       "0   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "1   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "2                   [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]   \n",
       "3   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "4   [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "5   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "6   [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "7   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "8   [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "9   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "10  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "11  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "12  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "13  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "14  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "15  [0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0...   \n",
       "16  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "17  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "18  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "19  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "\n",
       "                                            technique  \n",
       "0                                               Doubt  \n",
       "1                                     Loaded Language  \n",
       "2                                               Doubt  \n",
       "3                                              Smears  \n",
       "4                                     Loaded Language  \n",
       "5                                     Loaded Language  \n",
       "6                                               Doubt  \n",
       "7                          Thought-terminating cliché  \n",
       "8                                         Flag-waving  \n",
       "9                                     Loaded Language  \n",
       "10                          Causal Oversimplification  \n",
       "11                                    Loaded Language  \n",
       "12  Misrepresentation of Someone's Position (Straw...  \n",
       "13                          Causal Oversimplification  \n",
       "14                                    Loaded Language  \n",
       "15                                    Loaded Language  \n",
       "16                                    Loaded Language  \n",
       "17                              Name calling/Labeling  \n",
       "18                           Appeal to fear/prejudice  \n",
       "19                           Appeal to fear/prejudice  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(x):\n",
    "    x = x[1:-1].split()\n",
    "    x = list(map(int, x))\n",
    "    return x\n",
    "\n",
    "data_pd[\"prop_mask\"] = data_pd[\"prop_mask\"].apply(lambda x: make_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "f21694c44af3473db1a03a8872efc7ba",
      "f389e887e8dd43c5a93cb9bd172d1913",
      "2928d886b29c4dc5a21b85ecec70905f",
      "c40f2241970e48d5814282f1d78c4396",
      "fbad4c6f245449b781423089b70475a7",
      "169d5450fc7c4bfdb88d76fd0c942852",
      "6353f804a8304e68a638f6db27c8ebd7",
      "f8e0bd9d3ffe45dfb6d2c7765ea7500b",
      "9b1778789915413091dc2aedbf078adb",
      "55c039342f0d4a9da3f72867dafdf952",
      "ab7f40ac574346e5aff9d0fd65c7e197",
      "02bf06ed8c8b4c049c96e990e9fd837d",
      "5eb8475df57047c8b24401e038a12d7b",
      "6f6807a0e1fb4ca8a183e59d80138265",
      "47db5fbd04684483af9f2a237d492311",
      "45801f788fe24845be510e49fde1e2df"
     ]
    },
    "id": "jNgxuUNFpMEu",
    "outputId": "fa489f5a-2468-42e2-caa6-b5b929f38f81"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SpanBERT/spanbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q3DUO1DTpMEu"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data, max_len=250):\n",
    "    col_input_ids = []\n",
    "    col_attention_mask = []\n",
    "    col_token_type_ids = []\n",
    "    col_token_prop_mask = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        token_text = tokenizer.encode_plus(\n",
    "            data[\"text\"][i], \n",
    "            return_offsets_mapping=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        token_count = len(token_text.input_ids)\n",
    "        token_prop_mask = [0] * max_len\n",
    "        for j, (ind_s, ind_e) in enumerate(token_text.offset_mapping):\n",
    "            if sum(data[\"prop_mask\"][i][ind_s:ind_e]) > 0:\n",
    "                #print(data[\"text\"][i][ind_s:ind_e], 109)\n",
    "                token_prop_mask[j] = 1\n",
    "            \n",
    "        col_token_prop_mask.append(token_prop_mask) \n",
    "\n",
    "        token_technique = tokenizer.encode_plus(\n",
    "            data[\"technique\"][i], \n",
    "            return_offsets_mapping=True, \n",
    "            max_length=max_len, \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids = token_text.input_ids + token_technique.input_ids[1:]\n",
    "        token_type_ids = [0] * token_count + [1] * len(token_technique.input_ids[1:])\n",
    "        len_input_ids = len(input_ids)\n",
    "        attention_mask = [1] * len_input_ids\n",
    "\n",
    "        assert max_len > len_input_ids, f\"max_len {max_len} <= len_input_ids {len_input_ids}\"\n",
    "        \n",
    "        padding = [0] * (max_len - len_input_ids)\n",
    "        col_input_ids.append(input_ids + padding)\n",
    "        col_attention_mask.append(attention_mask + padding)\n",
    "        col_token_type_ids.append(token_type_ids + padding)\n",
    "\n",
    "        #if sum(token_prop_mask) > 0:\n",
    "        #    print(data[\"technique\"][i])\n",
    "        #    print(data[\"text\"][i])\n",
    "        #    inp_ids = np.array(input_ids + padding)\n",
    "        #    mask_ids = np.array(token_prop_mask)\n",
    "        #    np_text = np.array(list(data[\"text\"][i]))\n",
    "        #    np_prop = np.array(data[\"prop_mask\"][i])\n",
    "        #    my_tok = inp_ids[mask_ids == 1] \n",
    "        #    prop_mask = data[\"prop_mask\"][i]\n",
    "        #    print(\"|\", \"\".join(np_text[np_prop == 1]), \"|\")\n",
    "        #    print(tokenizer.decode(my_tok))\n",
    "        #    return\n",
    "        \n",
    "    return col_input_ids, col_attention_mask, col_token_type_ids, col_token_prop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a6W-rHObpMEv"
   },
   "outputs": [],
   "source": [
    "col_input_ids, col_attention_mask, col_token_type_ids, col_token_prop_mask = preprocessing(data_pd)\n",
    "data_pd[\"col_input_ids\"] = col_input_ids\n",
    "data_pd[\"col_attention_mask\"] = col_attention_mask\n",
    "data_pd[\"col_token_type_ids\"] = col_token_type_ids\n",
    "data_pd[\"col_token_prop_mask\"] = col_token_prop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "CHI99lu0lh48",
    "outputId": "a779a041-dfe7-425c-93ca-52a3d26ddd7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "      <th>col_token_prop_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which leads me then to wonder: If they're real...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[101, 1134, 4501, 1143, 1173, 1106, 4608, 131,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Putting aside freedom of speech, the persecuti...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 4518, 4783, 4438, 1104, 4055, 117, 1103,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No fact-checking</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[101, 1185, 1864, 118, 9444, 102, 4095, 102, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THAT'S A FACT \\n\\nDID YOU KNOW THE NRA TRAINED...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Smears</td>\n",
       "      <td>[101, 1115, 112, 188, 170, 1864, 1225, 1128, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It may even prove a political masterstroke of ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1122, 1336, 1256, 5424, 170, 1741, 11573...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This was, remember, 1965, four years before th...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1142, 1108, 117, 2676, 117, 2679, 117, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>But to see the partisans of the defeated candi...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[101, 1133, 1106, 1267, 1103, 17696, 1116, 110...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LIBERAL LOGIC: \"DON'T CALL THEM ANIMALS!\"\\n\\n\"...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Thought-terminating cliché</td>\n",
       "      <td>[101, 7691, 8738, 131, 107, 1274, 112, 189, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Orban is openly Christian and seems to underst...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Flag-waving</td>\n",
       "      <td>[101, 1137, 7167, 1110, 9990, 22572, 12937, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The handover was done with much fanfare, then ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1103, 1289, 5909, 1108, 1694, 1114, 1277...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The people who talk about the \"Jewish question...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "      <td>[101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The “Countering Violent Extremism” is trash an...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1103, 789, 4073, 1158, 5973, 4252, 7877,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I BULLSHITTED AND USED BLACKS AND MINORITIES T...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Misrepresentation of Someone's Position (Straw...</td>\n",
       "      <td>[101, 178, 17480, 1906, 1105, 1215, 14892, 110...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>They deliberately refused to bring up the alle...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "      <td>[101, 1152, 9938, 3347, 1106, 2498, 1146, 1103...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Despite the fall of his friend Pineda, Maradia...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 2693, 1103, 2303, 1104, 1117, 1910, 1019...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>If we wipe out the Coronavirus when the warm w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1191, 1195, 14182, 1149, 1103, 1884, 157...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Perhaps Arizona will put someone in that actua...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 3229, 170, 28021, 7637, 1209, 1508, 1800...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOW DARE YOU NOT VOTERINO FOR HECKIN' BERNERIN...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "      <td>[101, 1293, 9164, 1128, 1136, 16977, 4559, 111...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Less than a week later, Wilson received a lett...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Appeal to fear/prejudice</td>\n",
       "      <td>[101, 1750, 1190, 170, 1989, 1224, 117, 192, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The ideology that killed over 100 million last...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Appeal to fear/prejudice</td>\n",
       "      <td>[101, 1103, 14270, 1115, 1841, 1166, 1620, 155...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Which leads me then to wonder: If they're real...   \n",
       "1   Putting aside freedom of speech, the persecuti...   \n",
       "2                                    No fact-checking   \n",
       "3   THAT'S A FACT \\n\\nDID YOU KNOW THE NRA TRAINED...   \n",
       "4   It may even prove a political masterstroke of ...   \n",
       "5   This was, remember, 1965, four years before th...   \n",
       "6   But to see the partisans of the defeated candi...   \n",
       "7   LIBERAL LOGIC: \"DON'T CALL THEM ANIMALS!\"\\n\\n\"...   \n",
       "8   Orban is openly Christian and seems to underst...   \n",
       "9   The handover was done with much fanfare, then ...   \n",
       "10  The people who talk about the \"Jewish question...   \n",
       "11  The “Countering Violent Extremism” is trash an...   \n",
       "12  I BULLSHITTED AND USED BLACKS AND MINORITIES T...   \n",
       "13  They deliberately refused to bring up the alle...   \n",
       "14  Despite the fall of his friend Pineda, Maradia...   \n",
       "15  If we wipe out the Coronavirus when the warm w...   \n",
       "16  Perhaps Arizona will put someone in that actua...   \n",
       "17  HOW DARE YOU NOT VOTERINO FOR HECKIN' BERNERIN...   \n",
       "18  Less than a week later, Wilson received a lett...   \n",
       "19  The ideology that killed over 100 million last...   \n",
       "\n",
       "                                            prop_mask  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "17  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                            technique  \\\n",
       "0                                               Doubt   \n",
       "1                                     Loaded Language   \n",
       "2                                               Doubt   \n",
       "3                                              Smears   \n",
       "4                                     Loaded Language   \n",
       "5                                     Loaded Language   \n",
       "6                                               Doubt   \n",
       "7                          Thought-terminating cliché   \n",
       "8                                         Flag-waving   \n",
       "9                                     Loaded Language   \n",
       "10                          Causal Oversimplification   \n",
       "11                                    Loaded Language   \n",
       "12  Misrepresentation of Someone's Position (Straw...   \n",
       "13                          Causal Oversimplification   \n",
       "14                                    Loaded Language   \n",
       "15                                    Loaded Language   \n",
       "16                                    Loaded Language   \n",
       "17                              Name calling/Labeling   \n",
       "18                           Appeal to fear/prejudice   \n",
       "19                           Appeal to fear/prejudice   \n",
       "\n",
       "                                        col_input_ids  \\\n",
       "0   [101, 1134, 4501, 1143, 1173, 1106, 4608, 131,...   \n",
       "1   [101, 4518, 4783, 4438, 1104, 4055, 117, 1103,...   \n",
       "2   [101, 1185, 1864, 118, 9444, 102, 4095, 102, 0...   \n",
       "3   [101, 1115, 112, 188, 170, 1864, 1225, 1128, 1...   \n",
       "4   [101, 1122, 1336, 1256, 5424, 170, 1741, 11573...   \n",
       "5   [101, 1142, 1108, 117, 2676, 117, 2679, 117, 1...   \n",
       "6   [101, 1133, 1106, 1267, 1103, 17696, 1116, 110...   \n",
       "7   [101, 7691, 8738, 131, 107, 1274, 112, 189, 18...   \n",
       "8   [101, 1137, 7167, 1110, 9990, 22572, 12937, 18...   \n",
       "9   [101, 1103, 1289, 5909, 1108, 1694, 1114, 1277...   \n",
       "10  [101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...   \n",
       "11  [101, 1103, 789, 4073, 1158, 5973, 4252, 7877,...   \n",
       "12  [101, 178, 17480, 1906, 1105, 1215, 14892, 110...   \n",
       "13  [101, 1152, 9938, 3347, 1106, 2498, 1146, 1103...   \n",
       "14  [101, 2693, 1103, 2303, 1104, 1117, 1910, 1019...   \n",
       "15  [101, 1191, 1195, 14182, 1149, 1103, 1884, 157...   \n",
       "16  [101, 3229, 170, 28021, 7637, 1209, 1508, 1800...   \n",
       "17  [101, 1293, 9164, 1128, 1136, 16977, 4559, 111...   \n",
       "18  [101, 1750, 1190, 170, 1989, 1224, 117, 192, 8...   \n",
       "19  [101, 1103, 14270, 1115, 1841, 1166, 1620, 155...   \n",
       "\n",
       "                                   col_attention_mask  \\\n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                   col_token_type_ids  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "12  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "17  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  col_token_prop_mask  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2   [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4   [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "6   [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "8   [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "10  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...  \n",
       "12  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...  \n",
       "17  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...  \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "19  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJzrCSPssmA3",
    "outputId": "6d12de0a-e783-42a4-efdd-ba4a3c43510b"
   },
   "outputs": [],
   "source": [
    "FRACTION = 0.1\n",
    "data_num = int(data_pd.shape[0] * FRACTION)\n",
    "\n",
    "data_pd = data_pd.sample(frac=1).reset_index(drop=True)\n",
    "sep_dev_pd = data_pd.iloc[:data_num,:]\n",
    "sep_train_pd = data_pd.iloc[data_num:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "C6pY6bfepMEw",
    "outputId": "c06c784f-1a44-440b-b15e-149c3658ba6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "      <th>col_token_prop_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If we wipe out the Coronavirus when the warm w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1191, 1195, 14182, 1149, 1103, 1884, 157...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people who talk about the \"Jewish question...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "      <td>[101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  If we wipe out the Coronavirus when the warm w...   \n",
       "1  The people who talk about the \"Jewish question...   \n",
       "\n",
       "                                           prop_mask  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                   technique  \\\n",
       "0            Loaded Language   \n",
       "1  Causal Oversimplification   \n",
       "\n",
       "                                       col_input_ids  \\\n",
       "0  [101, 1191, 1195, 14182, 1149, 1103, 1884, 157...   \n",
       "1  [101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...   \n",
       "\n",
       "                                  col_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                  col_token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 col_token_prop_mask  \n",
       "0  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_dev_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6J9liVnFlzvs"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config, PATH):\n",
    "        super(Model, self).__init__(config)\n",
    "        self.bert = transformers.BertModel.from_pretrained(PATH)\n",
    "        self.linear = nn.Linear(1024, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        embedding = self.bert(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )[0]\n",
    "        logits = self.linear(embedding)\n",
    "        logits = self.flatten(logits)\n",
    "        result = self.sigm(logits)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "80PozV5KpMEx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = 'tune_model/squad2'\n",
    "\n",
    "bert = transformers.BertModel.from_pretrained(PATH)\n",
    "my_model = Model(bert.config, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qZ0Xr8kUpMEx"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=1e-2)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0Ap5F7ZCqvV1",
    "outputId": "03c29c66-a415-44c4-985a-9319c01b7d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbXb-N_Yq9yP",
    "outputId": "b28ea17b-0b81-45ce-e5b1-893ff5dee914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "my_model.to(dev)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "      <th>col_token_prop_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If we wipe out the Coronavirus when the warm w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1191, 1195, 14182, 1149, 1103, 1884, 157...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people who talk about the \"Jewish question...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Causal Oversimplification</td>\n",
       "      <td>[101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  If we wipe out the Coronavirus when the warm w...   \n",
       "1  The people who talk about the \"Jewish question...   \n",
       "\n",
       "                                           prop_mask  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                   technique  \\\n",
       "0            Loaded Language   \n",
       "1  Causal Oversimplification   \n",
       "\n",
       "                                       col_input_ids  \\\n",
       "0  [101, 1191, 1195, 14182, 1149, 1103, 1884, 157...   \n",
       "1  [101, 1103, 1234, 1150, 2037, 1164, 1103, 107,...   \n",
       "\n",
       "                                  col_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                  col_token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 col_token_prop_mask  \n",
       "0  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_dev_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "GTm9IklVnejX",
    "outputId": "811ef70f-7fd1-44ea-ac4c-bd0d9010b6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technique: Loaded Language\n",
      "---\n",
      "text: If we wipe out the Coronavirus when the warm weather comes we can tell the liberals that Global Warming killed it and watch their heads explode!\n",
      "\n",
      "---\n",
      "ans: [CLS]\n",
      "---\n",
      "true ans: wipe out global warming killed heads explode!\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "text_check(my_model, i, 0.5, sep_dev_pd, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPxrVF-ZpMEy",
    "outputId": "c12f237b-e901-4421-ed46-e3f753986a07"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0: \n",
      "train_loss = 2.226478338241577, \n",
      "dev_loss = 0.4069599509239197\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-59f6de92467b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nepoch {epoch}: \\ntrain_loss = {train_loss}, \\ndev_loss = {dev_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mcheck_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_dev_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Diplom/learning_checks.py\u001b[0m in \u001b[0;36mcheck_metrics\u001b[0;34m(model, data, line, dev)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col_token_prop_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0msum_tens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "EPOCHS = 4\n",
    "batch_size = 5\n",
    "dev_batch_size = 10\n",
    "N = len(sep_train_pd)\n",
    "M = len(sep_dev_pd)\n",
    "data = sep_train_pd.values\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "F = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    my_model.train()\n",
    "    train_loss = 0\n",
    "    for i in tqdm(range(0, N, batch_size), leave=False):\n",
    "        start = i\n",
    "        end = i + batch_size if i + batch_size < N else N\n",
    "        ids = torch.tensor(list(sep_train_pd[\"col_input_ids\"][start:end])).to(dev)\n",
    "        attention_mask = torch.tensor(list(sep_train_pd[\"col_attention_mask\"][start:end])).to(dev)\n",
    "        type_ids = torch.tensor(list(sep_train_pd[\"col_token_type_ids\"][start:end])).to(dev)\n",
    "        target = torch.tensor(list(sep_train_pd[\"col_token_prop_mask\"][start:end]), dtype=torch.float).to(dev)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = my_model(ids, attention_mask, type_ids)\n",
    "        output = torch.squeeze(output, dim=1)\n",
    "        loss = criterion(output, target * 0.99)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    dev_loss = 0\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, M, dev_batch_size):\n",
    "            start = i\n",
    "            end = i + dev_batch_size if i + dev_batch_size < M else M\n",
    "            ids = torch.tensor(list(sep_dev_pd[\"col_input_ids\"][start:end])).to(dev)\n",
    "            attention_mask = torch.tensor(list(sep_dev_pd[\"col_attention_mask\"][start:end])).to(dev)\n",
    "            type_ids = torch.tensor(list(sep_dev_pd[\"col_token_type_ids\"][start:end])).to(dev)\n",
    "            target = torch.tensor(list(sep_dev_pd[\"col_token_prop_mask\"][start:end]), dtype=torch.float).to(dev)\n",
    "            \n",
    "            output = my_model(ids, attention_mask, type_ids)\n",
    "            output = torch.squeeze(output, dim=1)\n",
    "            loss = criterion(output, target * 0.99)\n",
    "            dev_loss += loss\n",
    "        print(f\"\\nepoch {epoch}: \\ntrain_loss = {train_loss}, \\ndev_loss = {dev_loss}\")\n",
    "    check_metrics(my_model, sep_dev_pd, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sk1domLiNFLR",
    "outputId": "5859f3f6-5e68-4cb3-f728-ea6f7434b816"
   },
   "outputs": [],
   "source": [
    "check_metrics(my_model, sep_dev_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfKKOr6kqphh"
   },
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), \"models/model.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "diplom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02bf06ed8c8b4c049c96e990e9fd837d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45801f788fe24845be510e49fde1e2df",
      "placeholder": "​",
      "style": "IPY_MODEL_47db5fbd04684483af9f2a237d492311",
      "value": " 213k/213k [00:01&lt;00:00, 194kB/s]"
     }
    },
    "169d5450fc7c4bfdb88d76fd0c942852": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2928d886b29c4dc5a21b85ecec70905f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_169d5450fc7c4bfdb88d76fd0c942852",
      "max": 413,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbad4c6f245449b781423089b70475a7",
      "value": 413
     }
    },
    "45801f788fe24845be510e49fde1e2df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47db5fbd04684483af9f2a237d492311": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55c039342f0d4a9da3f72867dafdf952": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb8475df57047c8b24401e038a12d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6353f804a8304e68a638f6db27c8ebd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f6807a0e1fb4ca8a183e59d80138265": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1778789915413091dc2aedbf078adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab7f40ac574346e5aff9d0fd65c7e197",
       "IPY_MODEL_02bf06ed8c8b4c049c96e990e9fd837d"
      ],
      "layout": "IPY_MODEL_55c039342f0d4a9da3f72867dafdf952"
     }
    },
    "ab7f40ac574346e5aff9d0fd65c7e197": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f6807a0e1fb4ca8a183e59d80138265",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5eb8475df57047c8b24401e038a12d7b",
      "value": 213450
     }
    },
    "c40f2241970e48d5814282f1d78c4396": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8e0bd9d3ffe45dfb6d2c7765ea7500b",
      "placeholder": "​",
      "style": "IPY_MODEL_6353f804a8304e68a638f6db27c8ebd7",
      "value": " 413/413 [00:01&lt;00:00, 263B/s]"
     }
    },
    "f21694c44af3473db1a03a8872efc7ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2928d886b29c4dc5a21b85ecec70905f",
       "IPY_MODEL_c40f2241970e48d5814282f1d78c4396"
      ],
      "layout": "IPY_MODEL_f389e887e8dd43c5a93cb9bd172d1913"
     }
    },
    "f389e887e8dd43c5a93cb9bd172d1913": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8e0bd9d3ffe45dfb6d2c7765ea7500b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbad4c6f245449b781423089b70475a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
