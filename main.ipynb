{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlDMgYm4lzvd"
   },
   "source": [
    "(https://keras.io/examples/nlp/text_extraction_with_bert/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nl2fRygIlzvi",
    "outputId": "c195a9d2-9d66-4fee-ec98-28e95655b5f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, BertTokenizerFast \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "v53lw-ErpMEr"
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "\"Reductio ad hitlerum\",\n",
    "\"Whataboutism\",\n",
    "\"Presenting Irrelevant Data (Red Herring)\",\n",
    "\"Doubt\",\n",
    "\"Slogans\",\n",
    "\"Appeal to fear/prejudice\",\n",
    "\"Obfuscation, Intentional vagueness, Confusion\",\n",
    "\"Misrepresentation of Someone's Position (Straw Man)\",\n",
    "\"Glittering generalities (Virtue)\",\n",
    "\"Appeal to authority\",\n",
    "\"Repetition\",\n",
    "\"Bandwagon\",\n",
    "\"Causal Oversimplification\",\n",
    "\"Name calling/Labeling\",\n",
    "\"Thought-terminating cliché\",\n",
    "\"Flag-waving\",\n",
    "\"Exaggeration/Minimisation\",\n",
    "\"Smears\",\n",
    "\"Loaded Language\",\n",
    "\"Black-and-white Fallacy/Dictatorship\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "97sQkMTNpMEt",
    "outputId": "ccc783ab-29a8-41ce-dac2-1c0a28665ada"
   },
   "outputs": [],
   "source": [
    "sep_train_pd = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Black-and-white Fallacy/Dictatorship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Slogans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Loaded Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>Smears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>“Policies like background checks on all gun sa...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Slogans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>The group also passed a resolution backing red...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Repetition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>“Policies like background checks on all gun sa...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Repetition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>“The U.S. Conference of Mayors will continue d...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Flag-waving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>“It’s time for our leaders in Washington to fo...</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>Flag-waving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7325 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0       THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n   \n",
       "1     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "2     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "3     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "4     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "...                                                 ...   \n",
       "7320  “Policies like background checks on all gun sa...   \n",
       "7321  The group also passed a resolution backing red...   \n",
       "7322  “Policies like background checks on all gun sa...   \n",
       "7323  “The U.S. Conference of Mayors will continue d...   \n",
       "7324  “It’s time for our leaders in Washington to fo...   \n",
       "\n",
       "                                              prop_mask  \\\n",
       "0     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "1     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "2     [0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0...   \n",
       "3     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "4     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...   \n",
       "...                                                 ...   \n",
       "7320  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "7321  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "7322  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "7323  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "7324  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...   \n",
       "\n",
       "                                 technique  \n",
       "0     Black-and-white Fallacy/Dictatorship  \n",
       "1                                  Slogans  \n",
       "2                    Name calling/Labeling  \n",
       "3                          Loaded Language  \n",
       "4                                   Smears  \n",
       "...                                    ...  \n",
       "7320                               Slogans  \n",
       "7321                            Repetition  \n",
       "7322                            Repetition  \n",
       "7323                           Flag-waving  \n",
       "7324                           Flag-waving  \n",
       "\n",
       "[7325 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(x):\n",
    "    x = x[1:-1].split()\n",
    "    x = list(map(int, x))\n",
    "    return x\n",
    "\n",
    "sep_train_pd[\"prop_mask\"] = sep_train_pd[\"prop_mask\"].apply(lambda x: make_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "f21694c44af3473db1a03a8872efc7ba",
      "f389e887e8dd43c5a93cb9bd172d1913",
      "2928d886b29c4dc5a21b85ecec70905f",
      "c40f2241970e48d5814282f1d78c4396",
      "fbad4c6f245449b781423089b70475a7",
      "169d5450fc7c4bfdb88d76fd0c942852",
      "6353f804a8304e68a638f6db27c8ebd7",
      "f8e0bd9d3ffe45dfb6d2c7765ea7500b",
      "9b1778789915413091dc2aedbf078adb",
      "55c039342f0d4a9da3f72867dafdf952",
      "ab7f40ac574346e5aff9d0fd65c7e197",
      "02bf06ed8c8b4c049c96e990e9fd837d",
      "5eb8475df57047c8b24401e038a12d7b",
      "6f6807a0e1fb4ca8a183e59d80138265",
      "47db5fbd04684483af9f2a237d492311",
      "45801f788fe24845be510e49fde1e2df"
     ]
    },
    "id": "jNgxuUNFpMEu",
    "outputId": "fa489f5a-2468-42e2-caa6-b5b929f38f81"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SpanBERT/spanbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "q3DUO1DTpMEu"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data, max_len=250):\n",
    "    col_input_ids = []\n",
    "    col_attention_mask = []\n",
    "    col_token_type_ids = []\n",
    "    col_token_prop_mask = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        token_text = tokenizer.encode_plus(\n",
    "            data[\"text\"][i], \n",
    "            return_offsets_mapping=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        token_count = len(token_text.input_ids)\n",
    "        token_prop_mask = [0] * max_len\n",
    "        for j, (ind_s, ind_e) in enumerate(token_text.offset_mapping):\n",
    "            if sum(data[\"prop_mask\"][i][ind_s:ind_e]) > 0:\n",
    "                #print(data[\"text\"][i][ind_s:ind_e], 109)\n",
    "                token_prop_mask[j] = 1\n",
    "            \n",
    "        col_token_prop_mask.append(token_prop_mask) \n",
    "\n",
    "        token_technique = tokenizer.encode_plus(\n",
    "            data[\"technique\"][i], \n",
    "            return_offsets_mapping=True, \n",
    "            max_length=max_len, \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids = token_text.input_ids + token_technique.input_ids[1:]\n",
    "        token_type_ids = [0] * token_count + [1] * len(token_technique.input_ids[1:])\n",
    "        len_input_ids = len(input_ids)\n",
    "        attention_mask = [1] * len_input_ids\n",
    "\n",
    "        assert max_len > len_input_ids, f\"max_len {max_len} <= len_input_ids {len_input_ids}\"\n",
    "        \n",
    "        padding = [0] * (max_len - len_input_ids)\n",
    "        col_input_ids.append(input_ids + padding)\n",
    "        col_attention_mask.append(attention_mask + padding)\n",
    "        col_token_type_ids.append(token_type_ids + padding)\n",
    "\n",
    "        #if sum(token_prop_mask) > 0:\n",
    "        #    print(data[\"technique\"][i])\n",
    "        #    print(data[\"text\"][i])\n",
    "        #    inp_ids = np.array(input_ids + padding)\n",
    "        #    mask_ids = np.array(token_prop_mask)\n",
    "        #    np_text = np.array(list(data[\"text\"][i]))\n",
    "        #    np_prop = np.array(data[\"prop_mask\"][i])\n",
    "        #    my_tok = inp_ids[mask_ids == 1] \n",
    "        #    prop_mask = data[\"prop_mask\"][i]\n",
    "        #    print(\"|\", \"\".join(np_text[np_prop == 1]), \"|\")\n",
    "        #    print(tokenizer.decode(my_tok))\n",
    "        #    return\n",
    "        \n",
    "    return col_input_ids, col_attention_mask, col_token_type_ids, col_token_prop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "a6W-rHObpMEv"
   },
   "outputs": [],
   "source": [
    "col_input_ids, col_attention_mask, col_token_type_ids, col_token_prop_mask = preprocessing(sep_train_pd)\n",
    "sep_train_pd[\"col_input_ids\"] = col_input_ids\n",
    "sep_train_pd[\"col_attention_mask\"] = col_attention_mask\n",
    "sep_train_pd[\"col_token_type_ids\"] = col_token_type_ids\n",
    "sep_train_pd[\"col_token_prop_mask\"] = col_token_prop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "CHI99lu0lh48",
    "outputId": "a779a041-dfe7-425c-93ca-52a3d26ddd7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "      <th>col_token_prop_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Black-and-white Fallacy/Dictatorship</td>\n",
       "      <td>[101, 1175, 1132, 1178, 1160, 5772, 1116, 2130...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>[101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "      <td>[101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Smears</td>\n",
       "      <td>[101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>“Policies like background checks on all gun sa...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>[101, 789, 5502, 1176, 3582, 15008, 1113, 1155...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>The group also passed a resolution backing red...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>[101, 1103, 1372, 1145, 2085, 170, 6021, 4581,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>“Policies like background checks on all gun sa...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>[101, 789, 5502, 1176, 3582, 15008, 1113, 1155...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>“The U.S. Conference of Mayors will continue d...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Flag-waving</td>\n",
       "      <td>[101, 789, 1103, 190, 119, 188, 119, 3511, 110...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>“It’s time for our leaders in Washington to fo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Flag-waving</td>\n",
       "      <td>[101, 789, 1122, 787, 188, 1159, 1111, 1412, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7325 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0       THERE ARE ONLY TWO GENDERS\\n\\nFEMALE \\n\\nMALE\\n   \n",
       "1     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "2     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "3     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "4     SO BERNIE BROS HAVEN'T COMMITTED VIOLENCE EH?\\...   \n",
       "...                                                 ...   \n",
       "7320  “Policies like background checks on all gun sa...   \n",
       "7321  The group also passed a resolution backing red...   \n",
       "7322  “Policies like background checks on all gun sa...   \n",
       "7323  “The U.S. Conference of Mayors will continue d...   \n",
       "7324  “It’s time for our leaders in Washington to fo...   \n",
       "\n",
       "                                              prop_mask  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "7320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7321  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7322  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7323  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7324  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 technique  \\\n",
       "0     Black-and-white Fallacy/Dictatorship   \n",
       "1                                  Slogans   \n",
       "2                    Name calling/Labeling   \n",
       "3                          Loaded Language   \n",
       "4                                   Smears   \n",
       "...                                    ...   \n",
       "7320                               Slogans   \n",
       "7321                            Repetition   \n",
       "7322                            Repetition   \n",
       "7323                           Flag-waving   \n",
       "7324                           Flag-waving   \n",
       "\n",
       "                                          col_input_ids  \\\n",
       "0     [101, 1175, 1132, 1178, 1160, 5772, 1116, 2130...   \n",
       "1     [101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...   \n",
       "2     [101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...   \n",
       "3     [101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...   \n",
       "4     [101, 1177, 1129, 4558, 1663, 9304, 2155, 3983...   \n",
       "...                                                 ...   \n",
       "7320  [101, 789, 5502, 1176, 3582, 15008, 1113, 1155...   \n",
       "7321  [101, 1103, 1372, 1145, 2085, 170, 6021, 4581,...   \n",
       "7322  [101, 789, 5502, 1176, 3582, 15008, 1113, 1155...   \n",
       "7323  [101, 789, 1103, 190, 119, 188, 119, 3511, 110...   \n",
       "7324  [101, 789, 1122, 787, 188, 1159, 1111, 1412, 3...   \n",
       "\n",
       "                                     col_attention_mask  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "7320  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7321  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7322  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7323  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7324  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                     col_token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "7320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7321  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7322  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7323  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7324  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    col_token_prop_mask  \n",
       "0     [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2     [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "4     [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "7320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7321  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7322  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7323  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7324  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[7325 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJzrCSPssmA3",
    "outputId": "6d12de0a-e783-42a4-efdd-ba4a3c43510b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-e6ccef707bb5>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sep_dev_pd = pd.DataFrame(np.array([texts, prop_mask, techniques]).T,\n"
     ]
    }
   ],
   "source": [
    "dev_pd = pd.read_json(\"data1/dev_set_task2.txt\")\n",
    "\n",
    "texts, prop_mask, techniques = separation_of_topics(dev_pd)\n",
    "sep_dev_pd = pd.DataFrame(np.array([texts, prop_mask, techniques]).T,\n",
    "                            columns = [\"text\", \"prop_mask\", \"technique\"])\n",
    "col_input_ids, col_attention_mask, col_token_type_ids, col_token_prop_mask = preprocessing(sep_dev_pd)\n",
    "sep_dev_pd[\"col_input_ids\"] = col_input_ids\n",
    "sep_dev_pd[\"col_attention_mask\"] = col_attention_mask\n",
    "sep_dev_pd[\"col_token_type_ids\"] = col_token_type_ids\n",
    "sep_dev_pd[\"col_token_prop_mask\"] = col_token_prop_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "C6pY6bfepMEw",
    "outputId": "c06c784f-1a44-440b-b15e-149c3658ba6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prop_mask</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "      <th>col_token_prop_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOE  VERSUS THE VOLCANIC KREMLIN DON\\n\\n\"WILL ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 179, 7745, 6055, 1103, 12069, 180, 16996...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOE  VERSUS THE VOLCANIC KREMLIN DON\\n\\n\"WILL ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "      <td>[101, 179, 7745, 6055, 1103, 12069, 180, 16996...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Never thought l'd die fighting IRRESPONSIBLY R...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Exaggeration/Minimisation</td>\n",
       "      <td>[101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Never thought l'd die fighting IRRESPONSIBLY R...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Never thought l'd die fighting IRRESPONSIBLY R...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "      <td>[101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Deceitful\\nObnoxious\\nNarcissist\\nArrogant\\nLy...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1260, 2093, 2875, 2365, 184, 1830, 2728,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Deceitful\\nObnoxious\\nNarcissist\\nArrogant\\nLy...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Name calling/Labeling</td>\n",
       "      <td>[101, 1260, 2093, 2875, 2365, 184, 1830, 2728,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Got 195,000 + Americans KILLED.\\nFought scient...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Appeal to fear/prejudice</td>\n",
       "      <td>[101, 1400, 18500, 117, 1288, 116, 1821, 26237...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Got 195,000 + Americans KILLED.\\nFought scient...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 1400, 18500, 117, 1288, 116, 1821, 26237...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Got 195,000 + Americans KILLED.\\nFought scient...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>Smears</td>\n",
       "      <td>[101, 1400, 18500, 117, 1288, 116, 1821, 26237...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    JOE  VERSUS THE VOLCANIC KREMLIN DON\\n\\n\"WILL ...   \n",
       "1    JOE  VERSUS THE VOLCANIC KREMLIN DON\\n\\n\"WILL ...   \n",
       "2    Never thought l'd die fighting IRRESPONSIBLY R...   \n",
       "3    Never thought l'd die fighting IRRESPONSIBLY R...   \n",
       "4    Never thought l'd die fighting IRRESPONSIBLY R...   \n",
       "..                                                 ...   \n",
       "118  Deceitful\\nObnoxious\\nNarcissist\\nArrogant\\nLy...   \n",
       "119  Deceitful\\nObnoxious\\nNarcissist\\nArrogant\\nLy...   \n",
       "120  Got 195,000 + Americans KILLED.\\nFought scient...   \n",
       "121  Got 195,000 + Americans KILLED.\\nFought scient...   \n",
       "122  Got 195,000 + Americans KILLED.\\nFought scient...   \n",
       "\n",
       "                                             prop_mask  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "118  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "119  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "121  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "122  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                     technique  \\\n",
       "0              Loaded Language   \n",
       "1        Name calling/Labeling   \n",
       "2    Exaggeration/Minimisation   \n",
       "3              Loaded Language   \n",
       "4        Name calling/Labeling   \n",
       "..                         ...   \n",
       "118            Loaded Language   \n",
       "119      Name calling/Labeling   \n",
       "120   Appeal to fear/prejudice   \n",
       "121            Loaded Language   \n",
       "122                     Smears   \n",
       "\n",
       "                                         col_input_ids  \\\n",
       "0    [101, 179, 7745, 6055, 1103, 12069, 180, 16996...   \n",
       "1    [101, 179, 7745, 6055, 1103, 12069, 180, 16996...   \n",
       "2    [101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...   \n",
       "3    [101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...   \n",
       "4    [101, 1309, 1354, 181, 112, 173, 2939, 2935, 1...   \n",
       "..                                                 ...   \n",
       "118  [101, 1260, 2093, 2875, 2365, 184, 1830, 2728,...   \n",
       "119  [101, 1260, 2093, 2875, 2365, 184, 1830, 2728,...   \n",
       "120  [101, 1400, 18500, 117, 1288, 116, 1821, 26237...   \n",
       "121  [101, 1400, 18500, 117, 1288, 116, 1821, 26237...   \n",
       "122  [101, 1400, 18500, 117, 1288, 116, 1821, 26237...   \n",
       "\n",
       "                                    col_attention_mask  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "..                                                 ...   \n",
       "118  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "119  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "120  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "121  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "122  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                    col_token_type_ids  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "119  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "120  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "121  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "122  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                   col_token_prop_mask  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "1    [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "..                                                 ...  \n",
       "118  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "119  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "120  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "121  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "122  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[123 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_dev_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "6J9liVnFlzvs"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config, PATH):\n",
    "        super(Model, self).__init__(config)\n",
    "        self.bert = transformers.BertModel.from_pretrained(PATH)\n",
    "        self.linear = nn.Linear(1024, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        embedding = self.bert(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )[0]\n",
    "        logits = self.linear(embedding)\n",
    "        logits = self.flatten(logits)\n",
    "        result = self.sigm(logits)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "80PozV5KpMEx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = 'tune_model/squad2'\n",
    "\n",
    "bert = transformers.BertModel.from_pretrained(PATH)\n",
    "my_model = Model(bert.config, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qZ0Xr8kUpMEx"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=1e-2)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0Ap5F7ZCqvV1",
    "outputId": "03c29c66-a415-44c4-985a-9319c01b7d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbXb-N_Yq9yP",
    "outputId": "b28ea17b-0b81-45ce-e5b1-893ff5dee914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "my_model.to(dev)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "NEL7Punk1pVl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hist_graph(model, i, line):\n",
    "    #take data\n",
    "    ids = torch.tensor([list(sep_dev_pd[\"col_input_ids\"][i])]).to(dev)\n",
    "    attention_mask = torch.tensor([list(sep_dev_pd[\"col_attention_mask\"][i])]).to(dev)\n",
    "    type_ids = torch.tensor([list(sep_dev_pd[\"col_token_type_ids\"][i])]).to(dev)\n",
    "    #take model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ans_seq_tok = np.array(sep_dev_pd[\"col_input_ids\"][i])\n",
    "        output = model(ids, attention_mask, type_ids)\n",
    "        ans_mask = (torch.squeeze(output, dim=1)[0]).cpu()\n",
    "        plt.figure(figsize=(18,8))\n",
    "        words = []\n",
    "        end = 0\n",
    "        for j in range(len(ans_seq_tok)):\n",
    "            if ans_seq_tok[j] == 102:\n",
    "                end = j\n",
    "                break\n",
    "            words += [tokenizer.decode(int(ans_seq_tok[j])) + \"_\" + str(j)]\n",
    "        plt.hlines(line, xmin=0, xmax=end, color ='r')\n",
    "        plt.plot(words, ans_mask[:end], drawstyle='steps-mid', label='steps-mid', color ='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "dIUyq_K33HbU"
   },
   "outputs": [],
   "source": [
    "def text_check(model, i, line):\n",
    "    #take data\n",
    "    ids = torch.tensor([list(sep_dev_pd[\"col_input_ids\"][i])]).to(dev)\n",
    "    attention_mask = torch.tensor([list(sep_dev_pd[\"col_attention_mask\"][i])]).to(dev)\n",
    "    type_ids = torch.tensor([list(sep_dev_pd[\"col_token_type_ids\"][i])]).to(dev)\n",
    "    #take model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(ids, attention_mask, type_ids)\n",
    "        ans_mask = (torch.squeeze(output, dim=1)[0] > line).cpu()\n",
    "        if sum(ans_mask) > 0:\n",
    "            print(\"technique:\", sep_dev_pd[\"technique\"][i])\n",
    "            print(\"---\")\n",
    "            print(\"text:\", sep_dev_pd[\"text\"][i])\n",
    "            print(\"---\")\n",
    "            ans_seq_tok = np.array(sep_dev_pd[\"col_input_ids\"][i])[ans_mask == 1]\n",
    "            print(\"ans:\", tokenizer.decode(ans_seq_tok))\n",
    "            print(\"---\")\n",
    "            ans_mask = np.array(sep_dev_pd[\"col_token_prop_mask\"][i])\n",
    "            ans_seq_tok = np.array(sep_dev_pd[\"col_input_ids\"][i])[ans_mask == 1]\n",
    "            print(\"true ans:\", tokenizer.decode(ans_seq_tok))\n",
    "            print(\"---\")\n",
    "            hist_graph(my_model, 0, line)\n",
    "            plt.show()\n",
    "            return True\n",
    "        print(\"---\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "GTm9IklVnejX",
    "outputId": "811ef70f-7fd1-44ea-ac4c-bd0d9010b6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technique: Loaded Language\n",
      "---\n",
      "text: JOE  VERSUS THE VOLCANIC KREMLIN DON\n",
      "\n",
      "\"WILL YOU SHUT UP, MAN?\"\n",
      "\n",
      "LORD OF THE LIES\n",
      "---\n",
      "ans: [CLS]\n",
      "---\n",
      "true ans: shut up lord of the lies\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_check(my_model, 0, 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "8fZEuyYKFiAV"
   },
   "outputs": [],
   "source": [
    "def check_metrics(model, data, line=0.5):\n",
    "    batch_size = 10\n",
    "    M = data.shape[0]\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, M, batch_size):\n",
    "            start = i\n",
    "            end = i + batch_size if i + batch_size < M else M\n",
    "            ids = torch.tensor(list(data[\"col_input_ids\"][start:end])).to(dev)\n",
    "            attention_mask = torch.tensor(list(data[\"col_attention_mask\"][start:end])).to(dev)\n",
    "            type_ids = torch.tensor(list(data[\"col_token_type_ids\"][start:end])).to(dev)\n",
    "            target = torch.tensor(list(data[\"col_token_prop_mask\"][start:end]), dtype=torch.float).to(dev)\n",
    "            \n",
    "            output = my_model(ids, attention_mask, type_ids)\n",
    "            output = (torch.squeeze(output, dim=1) > line).type(torch.int16)\n",
    "            sum_tens = output + target\n",
    "            diff_tens = output - target\n",
    "            tp += (sum_tens == 2).sum().item()\n",
    "            fp += (diff_tens == 1).sum().item()\n",
    "            tn += (sum_tens == 0).sum().item()\n",
    "            fn += (diff_tens == -1).sum().item()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    F = 2 * precision * recall / (precision + recall)\n",
    "    print(f\"precision={precision}, recall={recall}, accuracy={accuracy}, F={F}\")\n",
    "    return precision, recall, accuracy, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPxrVF-ZpMEy",
    "outputId": "c12f237b-e901-4421-ed46-e3f753986a07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.725121359223301, recall=0.7104637336504162, accuracy=0.9402947154471545, F=0.7177177177177178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss = 33.466026306152344, dev_loss = 1.8760626316070557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.7587281795511222, recall=0.7235434007134364, accuracy=0.9458841463414634, F=0.740718198417529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 29.186553955078125, dev_loss = 1.6826038360595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.7254366812227074, recall=0.7901307966706302, accuracy=0.945630081300813, F=0.7564029595902106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss = 26.498409271240234, dev_loss = 1.7217918634414673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.7599531615925058, recall=0.7717003567181926, accuracy=0.9495680894308943, F=0.7657817109144543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss = 23.96092414855957, dev_loss = 1.644991397857666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.7509771077610273, recall=0.7996432818073722, accuracy=0.950266768292683, F=0.7745465015836451\n",
      "epoch 4: train_loss = 21.77276611328125, dev_loss = 1.5992634296417236\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "EPOCHS = 4\n",
    "batch_size = 5\n",
    "dev_batch_size = 10\n",
    "N = len(sep_train_pd)\n",
    "M = len(sep_dev_pd)\n",
    "data = sep_train_pd.values\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "F = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    my_model.train()\n",
    "    train_loss = 0\n",
    "    for i in tqdm.tqdm(range(0, N, batch_size), leave=False):\n",
    "        start = i\n",
    "        end = i + batch_size if i + batch_size < N else N\n",
    "        ids = torch.tensor(list(sep_train_pd[\"col_input_ids\"][start:end])).to(dev)\n",
    "        attention_mask = torch.tensor(list(sep_train_pd[\"col_attention_mask\"][start:end])).to(dev)\n",
    "        type_ids = torch.tensor(list(sep_train_pd[\"col_token_type_ids\"][start:end])).to(dev)\n",
    "        target = torch.tensor(list(sep_train_pd[\"col_token_prop_mask\"][start:end]), dtype=torch.float).to(dev)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = my_model(ids, attention_mask, type_ids)\n",
    "        output = torch.squeeze(output, dim=1)\n",
    "        loss = criterion(output, target * 0.99)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    dev_loss = 0\n",
    "    check_metrics(my_model, sep_dev_pd, 0.5)\n",
    "    my_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, M, dev_batch_size):\n",
    "            start = i\n",
    "            end = i + dev_batch_size if i + dev_batch_size < M else M\n",
    "            ids = torch.tensor(list(sep_dev_pd[\"col_input_ids\"][start:end])).to(dev)\n",
    "            attention_mask = torch.tensor(list(sep_dev_pd[\"col_attention_mask\"][start:end])).to(dev)\n",
    "            type_ids = torch.tensor(list(sep_dev_pd[\"col_token_type_ids\"][start:end])).to(dev)\n",
    "            target = torch.tensor(list(sep_dev_pd[\"col_token_prop_mask\"][start:end]), dtype=torch.float).to(dev)\n",
    "            \n",
    "            output = my_model(ids, attention_mask, type_ids)\n",
    "            output = torch.squeeze(output, dim=1)\n",
    "            loss = criterion(output, target * 0.99)\n",
    "            dev_loss += loss\n",
    "        print(f\"epoch {epoch}: train_loss = {train_loss}, dev_loss = {dev_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sk1domLiNFLR",
    "outputId": "5859f3f6-5e68-4cb3-f728-ea6f7434b816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.23191489361702128, recall=0.06480380499405469, accuracy=0.8771595528455285, F=0.10130111524163568\n"
     ]
    }
   ],
   "source": [
    "check_metrics(my_model, sep_dev_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfKKOr6kqphh"
   },
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), \"models/model.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "diplom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02bf06ed8c8b4c049c96e990e9fd837d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45801f788fe24845be510e49fde1e2df",
      "placeholder": "​",
      "style": "IPY_MODEL_47db5fbd04684483af9f2a237d492311",
      "value": " 213k/213k [00:01&lt;00:00, 194kB/s]"
     }
    },
    "169d5450fc7c4bfdb88d76fd0c942852": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2928d886b29c4dc5a21b85ecec70905f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_169d5450fc7c4bfdb88d76fd0c942852",
      "max": 413,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbad4c6f245449b781423089b70475a7",
      "value": 413
     }
    },
    "45801f788fe24845be510e49fde1e2df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47db5fbd04684483af9f2a237d492311": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55c039342f0d4a9da3f72867dafdf952": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb8475df57047c8b24401e038a12d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6353f804a8304e68a638f6db27c8ebd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f6807a0e1fb4ca8a183e59d80138265": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1778789915413091dc2aedbf078adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab7f40ac574346e5aff9d0fd65c7e197",
       "IPY_MODEL_02bf06ed8c8b4c049c96e990e9fd837d"
      ],
      "layout": "IPY_MODEL_55c039342f0d4a9da3f72867dafdf952"
     }
    },
    "ab7f40ac574346e5aff9d0fd65c7e197": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f6807a0e1fb4ca8a183e59d80138265",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5eb8475df57047c8b24401e038a12d7b",
      "value": 213450
     }
    },
    "c40f2241970e48d5814282f1d78c4396": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8e0bd9d3ffe45dfb6d2c7765ea7500b",
      "placeholder": "​",
      "style": "IPY_MODEL_6353f804a8304e68a638f6db27c8ebd7",
      "value": " 413/413 [00:01&lt;00:00, 263B/s]"
     }
    },
    "f21694c44af3473db1a03a8872efc7ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2928d886b29c4dc5a21b85ecec70905f",
       "IPY_MODEL_c40f2241970e48d5814282f1d78c4396"
      ],
      "layout": "IPY_MODEL_f389e887e8dd43c5a93cb9bd172d1913"
     }
    },
    "f389e887e8dd43c5a93cb9bd172d1913": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8e0bd9d3ffe45dfb6d2c7765ea7500b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbad4c6f245449b781423089b70475a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
