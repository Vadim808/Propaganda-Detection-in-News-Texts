{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS_PATH1 = \"data2/datasets1/train-articles\"\n",
    "LABELS_PATH1 = \"data2/datasets1/train-labels-task2-technique-classification\"\n",
    "\n",
    "TEXTS_PATH2 = \"data2/datasets2/train-articles\"\n",
    "LABELS_PATH2 = \"data2/datasets2/train-labels-task2-technique-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "TEXTS_NAMES1 = listdir(TEXTS_PATH1)\n",
    "TEXTS_NAMES2 = listdir(TEXTS_PATH2)\n",
    "PART_TEXT_NAMES = np.concatenate([TEXTS_NAMES1, TEXTS_NAMES2])\n",
    "\n",
    "LABELS_NAMES = []\n",
    "TEXTS_NAMES = []\n",
    "for i, name in enumerate(PART_TEXT_NAMES): \n",
    "    if i < len(TEXTS_NAMES1):\n",
    "        TEXTS_NAMES += [TEXTS_PATH1 + \"/\" + name]\n",
    "        LABELS_NAMES += [LABELS_PATH1 + \"/\" + name[:-3] + \"task2-TC.labels\"]\n",
    "    else:\n",
    "        TEXTS_NAMES += [TEXTS_PATH2 + \"/\" + name]\n",
    "        LABELS_NAMES += [LABELS_PATH2 + \"/\" + name[:-3] + \"task2-TC.labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels_file(label_path):\n",
    "    f = open(label_path, \"r\")\n",
    "    labels = []\n",
    "    for string in f:\n",
    "        num, technique, start, end = string.split(\"\\t\")\n",
    "        labels += [[int(start), int(end[:-1]), technique]]\n",
    "    labels.sort()\n",
    "    return labels\n",
    "\n",
    "def read_text_file(text_path):\n",
    "    f = open(text_path, \"r\")\n",
    "    return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_text(text, labels):\n",
    "    sep_data = []\n",
    "    positions = [0]\n",
    "    texts = text.split(\"\\n\")\n",
    "    ind = 0\n",
    "    for i in range(len(texts)):\n",
    "        ind += len(texts[i]) + 1\n",
    "        positions += [ind]\n",
    "    c_pos = 0\n",
    "    for label in labels:\n",
    "        while (positions[c_pos] <= label[0] < positions[c_pos + 1]) == 0:\n",
    "            c_pos += 1\n",
    "            if c_pos + 1 == len(positions):\n",
    "                return sep_data\n",
    "        left_edge = positions[c_pos]\n",
    "        sep_data += [[texts[c_pos], \n",
    "                      label[0] - left_edge,\n",
    "                      label[1] - left_edge,\n",
    "                      label[2]]]\n",
    "    return sep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_json_type(d):\n",
    "    el = [{\n",
    "            \"start\": d[1],\n",
    "            \"end\": d[2],\n",
    "            \"technique\": d[3]\n",
    "         }]\n",
    "    return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "texts = []\n",
    "data = []\n",
    "for i in range(len(TEXTS_NAMES)):\n",
    "    text_path = TEXTS_NAMES[i]\n",
    "    label_path = LABELS_NAMES[i]\n",
    "    labels = read_labels_file(label_path)\n",
    "    text = read_text_file(text_path)\n",
    "    sep_data = separate_text(text, labels)\n",
    "    if len(sep_data) == 0:\n",
    "        continue\n",
    "    c_text = sep_data[0][0]\n",
    "    label = []\n",
    "    for d in sep_data:\n",
    "        if d[0] == c_text:\n",
    "            label += add_json_type(d)\n",
    "        else:\n",
    "            if len(label) != 0:\n",
    "                data += [[c_text, label]]\n",
    "            c_text = d[0]\n",
    "            label = add_json_type(d)\n",
    "    data += [[c_text, label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.DataFrame(data, columns=[\"text\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Reductio ad hitlerum\",\n",
    "    \"Whataboutism\",\n",
    "    \"Presenting Irrelevant Data (Red Herring)\",\n",
    "    \"Doubt\",\n",
    "    \"Slogans\",\n",
    "    \"Appeal to fear/prejudice\",\n",
    "    \"Obfuscation, Intentional vagueness, Confusion\",\n",
    "    \"Misrepresentation of Someone's Position (Straw Man)\",\n",
    "    \"Glittering generalities (Virtue)\",\n",
    "    \"Appeal to authority\",\n",
    "    \"Repetition\",\n",
    "    \"Bandwagon\",\n",
    "    \"Causal Oversimplification\",\n",
    "    \"Name calling/Labeling\",\n",
    "    \"Thought-terminating cliché\",\n",
    "    \"Flag-waving\",\n",
    "    \"Exaggeration/Minimisation\",\n",
    "    \"Smears\",\n",
    "    \"Loaded Language\",\n",
    "    \"Black-and-white Fallacy/Dictatorship\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus_labels = [\n",
    "    \"Loaded_Language\",\n",
    "    \"Name_Calling,Labeling\",\n",
    "    \"Repetition\",\n",
    "    \"Exaggeration,Minimisation\",\n",
    "    \"Doubt\",\n",
    "    \"Appeal_to_fear-prejudice\",\n",
    "    \"Flag-Waving\",\n",
    "    \"Causal_Oversimplification\",\n",
    "    \"Slogans\",\n",
    "    \"Appeal_to_Authority\",\n",
    "    \"Black-and-White_Fallacy\",\n",
    "    \"Thought-terminating_Cliches\",\n",
    "    \"Whataboutism\",\n",
    "    \"Reductio_ad_Hitlerum\",\n",
    "    \"Red_Herring\",\n",
    "    \"Bandwagon\",\n",
    "    \"Obfuscation,Intentional_Vagueness,Confusion\",\n",
    "    \"Straw_Men\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus_labels.sort()\n",
    "labels.sort()\n",
    "labels.remove(\"Glittering generalities (Virtue)\")\n",
    "labels.remove(\"Misrepresentation of Someone's Position (Straw Man)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(new_corpus_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_change_labels = dict()\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    d_change_labels[new_corpus_labels[i]] = labels[i]\n",
    "\n",
    "d_change_labels[\"Straw_Men\"] = \"Misrepresentation of Someone's Position (Straw Man)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Appeal_to_Authority': 'Appeal to authority',\n",
       " 'Appeal_to_fear-prejudice': 'Appeal to fear/prejudice',\n",
       " 'Bandwagon': 'Bandwagon',\n",
       " 'Black-and-White_Fallacy': 'Black-and-white Fallacy/Dictatorship',\n",
       " 'Causal_Oversimplification': 'Causal Oversimplification',\n",
       " 'Doubt': 'Doubt',\n",
       " 'Exaggeration,Minimisation': 'Exaggeration/Minimisation',\n",
       " 'Flag-Waving': 'Flag-waving',\n",
       " 'Loaded_Language': 'Loaded Language',\n",
       " 'Name_Calling,Labeling': 'Name calling/Labeling',\n",
       " 'Obfuscation,Intentional_Vagueness,Confusion': 'Obfuscation, Intentional vagueness, Confusion',\n",
       " 'Red_Herring': 'Presenting Irrelevant Data (Red Herring)',\n",
       " 'Reductio_ad_Hitlerum': 'Reductio ad hitlerum',\n",
       " 'Repetition': 'Repetition',\n",
       " 'Slogans': 'Slogans',\n",
       " 'Straw_Men': \"Misrepresentation of Someone's Position (Straw Man)\",\n",
       " 'Thought-terminating_Cliches': 'Thought-terminating cliché',\n",
       " 'Whataboutism': 'Whataboutism'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_change_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_technique(old_t, name, data, i):\n",
    "    old_t[\"technique\"] = name\n",
    "    data[\"labels\"][i].append(old_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_name1 = [\"Bandwagon\", \"Reductio_ad_Hitlerum\"]\n",
    "wrong_name2 = [\"Whataboutism\", \"Straw_Men\", \"Red_Herring\"]\n",
    "\n",
    "def change_technique_name(data, d_change_labels):\n",
    "    for i in range(data.shape[0]):\n",
    "        N = len(data[\"labels\"][i])\n",
    "        j = 0\n",
    "        while j < N:\n",
    "            old_name = data[\"labels\"][i][j][\"technique\"]\n",
    "            if \"Bandwagon,Reductio_ad_hitlerum\" == old_name:\n",
    "                old_t = data[\"labels\"][i].pop(j)\n",
    "                for name in wrong_name1:\n",
    "                    correct_technique(old_t.copy(), name, data, i)\n",
    "                continue\n",
    "            if \"Whataboutism,Straw_Men,Red_Herring\" == old_name:\n",
    "                old_t = data[\"labels\"][i].pop(j)\n",
    "                for name in wrong_name2:\n",
    "                    correct_technique(old_t.copy(), name, data, i)\n",
    "                continue\n",
    "            new_name = d_change_labels[data[\"labels\"][i][j][\"technique\"]]\n",
    "            data[\"labels\"][i][j][\"technique\"] = new_name\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_technique_name(data_pd, d_change_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd.to_csv(\"data2/datasets1/new_data2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
