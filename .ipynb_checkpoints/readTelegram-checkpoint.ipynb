{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4md6QGwOvUZb",
    "outputId": "137982f7-4de0-478b-aa15-43e724100e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZilYxh6Ir2As",
    "outputId": "6be9f368-216d-4c72-939a-c9d3057bb1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "aosqMa1OrmBf"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    " \n",
    "with open(\"/content/drive/MyDrive/Diplom/ChatExport_2021-05-02/messages.html\", \"r\") as f:\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    texts = soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yhu57NearmBi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_text = []\n",
    "text_list = texts.split(\"\\n\")\n",
    "mes = \"Not included, change data exporting settings to download.\"\n",
    "for i in range(len(text_list)):\n",
    "    text = text_list[i]\n",
    "    if len(text) > 100 and text != mes:\n",
    "        ind = text.find(\"http\")\n",
    "        text = text[:ind]\n",
    "        result_text += [text]\n",
    "result_text = np.array(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "5W0OVo3YrmBj"
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "\"Reductio ad hitlerum\",\n",
    "\"Whataboutism\",\n",
    "\"Presenting Irrelevant Data (Red Herring)\",\n",
    "\"Doubt\",\n",
    "\"Slogans\",\n",
    "\"Appeal to fear/prejudice\",\n",
    "\"Obfuscation, Intentional vagueness, Confusion\",\n",
    "\"Misrepresentation of Someone's Position (Straw Man)\",\n",
    "\"Glittering generalities (Virtue)\",\n",
    "\"Appeal to authority\",\n",
    "\"Repetition\",\n",
    "\"Bandwagon\",\n",
    "\"Causal Oversimplification\",\n",
    "\"Name calling/Labeling\",\n",
    "\"Thought-terminating clich√©\",\n",
    "\"Flag-waving\",\n",
    "\"Exaggeration/Minimisation\",\n",
    "\"Smears\",\n",
    "\"Loaded Language\",\n",
    "\"Black-and-white Fallacy/Dictatorship\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Xyk4rxCtrmBk"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "trvLzpLqrmBk"
   },
   "outputs": [],
   "source": [
    "def preprocessing(texts, max_len=300):\n",
    "    col_input_ids = []\n",
    "    col_attention_mask = []\n",
    "    col_token_type_ids = []\n",
    "    technique = []\n",
    "    res_texts = []\n",
    "    \n",
    "    for i in range(texts.shape[0]):\n",
    "        token_text = tokenizer.encode_plus(\n",
    "            texts[i], \n",
    "            return_offsets_mapping=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        token_count = len(token_text.input_ids)\n",
    "        \n",
    "        for label in labels:\n",
    "            token_technique = tokenizer.encode_plus(\n",
    "                label, \n",
    "                return_offsets_mapping=True, \n",
    "                max_length=max_len, \n",
    "                truncation=True\n",
    "            )\n",
    "            input_ids = token_text.input_ids + token_technique.input_ids[1:]\n",
    "            token_type_ids = [0] * token_count + [1] * len(token_technique.input_ids[1:])\n",
    "            len_input_ids = len(input_ids)\n",
    "            attention_mask = [1] * len_input_ids\n",
    "            \n",
    "            if max_len < len_input_ids:\n",
    "                break\n",
    "\n",
    "            technique.append(label)\n",
    "            res_texts.append(texts[i])\n",
    "            padding = [0] * (max_len - len_input_ids)\n",
    "            col_input_ids.append(input_ids + padding)\n",
    "            col_attention_mask.append(attention_mask + padding)\n",
    "            col_token_type_ids.append(token_type_ids + padding)\n",
    "\n",
    "    return col_input_ids, col_attention_mask, col_token_type_ids, technique, res_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "691mnp2UrmBl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_input_ids, col_attention_mask, col_token_type_ids, technique, result_text = preprocessing(result_text, max_len=300)\n",
    "data_pd = pd.DataFrame()\n",
    "data_pd[\"text\"] = result_text\n",
    "data_pd[\"technique\"] = technique\n",
    "data_pd[\"col_input_ids\"] = col_input_ids\n",
    "data_pd[\"col_attention_mask\"] = col_attention_mask\n",
    "data_pd[\"col_token_type_ids\"] = col_token_type_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "aYWQb1R7rmBl"
   },
   "outputs": [],
   "source": [
    "def check_text(model, data, i, dev, line):\n",
    "    ids = torch.tensor([list(data[\"col_input_ids\"][i])]).to(dev)\n",
    "    attention_mask = torch.tensor([list(data[\"col_attention_mask\"][i])]).to(dev)\n",
    "    type_ids = torch.tensor([list(data[\"col_token_type_ids\"][i])]).to(dev)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(ids, attention_mask, type_ids)\n",
    "        ans_mask = (torch.squeeze(output, dim=1)[0] > line).cpu()\n",
    "        if sum(ans_mask) > 0:\n",
    "            print(\"technique:\", data[\"technique\"][i])\n",
    "            print(\"---\")\n",
    "            print(\"text:\", data[\"text\"][i])\n",
    "            print(\"---\")\n",
    "            ans_seq_tok = np.array(data[\"col_input_ids\"][i])[ans_mask == 1]\n",
    "            print(\"ans:\", tokenizer.decode(ans_seq_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "z6GypwDwxJld"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "class Model(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config, PATH):\n",
    "        super(Model, self).__init__(config)\n",
    "        self.bert = transformers.BertModel.from_pretrained(PATH)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        embedding = self.bert(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )[0]\n",
    "        logits = self.linear(embedding)\n",
    "        logits = self.flatten(logits)\n",
    "        result = self.sigm(logits)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "V8Kb7Eu3xpvN"
   },
   "outputs": [],
   "source": [
    "PATH = \"DeepPavlov/rubert-base-cased\"\n",
    "\n",
    "bert = transformers.BertModel.from_pretrained(PATH)\n",
    "model = Model(bert.config, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vw5RRPdrmBm",
    "outputId": "b5bf3971-8b61-43b7-a9a2-8b9a299ba33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "PATH = \"/content/drive/MyDrive/Diplom/model2.pth\"\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b98X3eJXwbid",
    "outputId": "fe7d192d-bbd7-446e-d552-cea4d12b8c7f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXp7JoxdyAYp",
    "outputId": "5089a1e3-1052-4c88-ec44-94082cb5e4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model.to(dev)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "csxsjKEPyVXX",
    "outputId": "bfceaa87-ee2e-4929-a982-103ce770943e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>technique</th>\n",
       "      <th>col_input_ids</th>\n",
       "      <th>col_attention_mask</th>\n",
       "      <th>col_token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏</td>\n",
       "      <td>Reductio ad hitlerum</td>\n",
       "      <td>[101, 3955, 10586, 34325, 14294, 13605, 1524, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏</td>\n",
       "      <td>Whataboutism</td>\n",
       "      <td>[101, 3955, 10586, 34325, 14294, 13605, 1524, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏</td>\n",
       "      <td>Presenting Irrelevant Data (Red Herring)</td>\n",
       "      <td>[101, 3955, 10586, 34325, 14294, 13605, 1524, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[101, 3955, 10586, 34325, 14294, 13605, 1524, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>[101, 3955, 10586, 34325, 14294, 13605, 1524, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15515</th>\n",
       "      <td>–í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª</td>\n",
       "      <td>Flag-waving</td>\n",
       "      <td>[101, 845, 60718, 842, 14072, 116804, 304, 287...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15516</th>\n",
       "      <td>–í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª</td>\n",
       "      <td>Exaggeration/Minimisation</td>\n",
       "      <td>[101, 845, 60718, 842, 14072, 116804, 304, 287...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517</th>\n",
       "      <td>–í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª</td>\n",
       "      <td>Smears</td>\n",
       "      <td>[101, 845, 60718, 842, 14072, 116804, 304, 287...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>–í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª</td>\n",
       "      <td>Loaded Language</td>\n",
       "      <td>[101, 845, 60718, 842, 14072, 116804, 304, 287...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519</th>\n",
       "      <td>–í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª</td>\n",
       "      <td>Black-and-white Fallacy/Dictatorship</td>\n",
       "      <td>[101, 845, 60718, 842, 14072, 116804, 304, 287...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15520 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  ...                                 col_token_type_ids\n",
       "0             10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "1             10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, ...\n",
       "2             10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "3             10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...\n",
       "4             10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...\n",
       "...                                       ...  ...                                                ...\n",
       "15515  –í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...\n",
       "15516  –í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...\n",
       "15517  –í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...\n",
       "15518  –í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...\n",
       "15519  –í –ú–æ—Å–∫–≤–µ –∞—Ä–µ—Å—Ç–æ–≤–∞–Ω –≥–ª–∞–≤—Ä–µ–¥ ¬´–ú–µ–¥–∏–∞–∑–æ–Ω—ã¬ª  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...\n",
       "\n",
       "[15520 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ao6CFEmgrmBm",
    "outputId": "cdf6fdca-cac2-442e-b07c-242ea279aaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technique: Reductio ad hitlerum\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Whataboutism\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Presenting Irrelevant Data (Red Herring)\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Doubt\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Slogans\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Appeal to fear/prejudice\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Obfuscation, Intentional vagueness, Confusion\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Misrepresentation of Someone's Position (Straw Man)\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Glittering generalities (Virtue)\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n",
      "technique: Appeal to authority\n",
      "---\n",
      "text: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –†–æ—Å—Å–∏–∏\n",
      "---\n",
      "ans: 10 —Å–∞–º—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ —Ä–æ—Å—Å–∏–∏\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    check_text(model, data_pd, i, dev, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "X9b2U896rmBn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "readTelegram.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
